{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github\\ICRA_25_workshop\\.nsai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RH20TDataset():\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.depth_path = r\"C:\\Users\\azahid\\Downloads\\RH20T_cfg2_depth\\RH20T_cfg2\"\n",
    "        self.root_dir_output = r'D:\\Github\\ICRA_25_workshop\\dataset_preparation\\dataset_depth_cameras_850_215'\n",
    "        self.camera = ['cam_104122061850', 'cam_036422060215']\n",
    "        # self.camera = ['cam_f0461559', 'cam_105422061350', 'cam_104422070044', 'cam_104422070042', 'cam_104122063678', 'cam_104122061850', 'cam_037522062165', 'cam_036422060215']\n",
    "        # self.camera = ['cam_f0461559']\n",
    "        self.task_file = []\n",
    "        self.keywords = [\"pick\"]\n",
    "        self.selected_task_dict = {kw: [] for kw in self.keywords}\n",
    "        self.pipeline()\n",
    "\n",
    "\n",
    "    def pipeline(self):\n",
    "        self.get_selected_task_ids()\n",
    "        for camera in self.camera:\n",
    "            for action in self.keywords:\n",
    "                self._get_all_task_dirs(action)\n",
    "                self.make_images_from_videos(action, camera)\n",
    "                # self.generate_proprioceptive_data(action, camera)\n",
    "\n",
    "\n",
    "        \n",
    "    def get_selected_task_ids(self):\n",
    "        task_desc_path = r'D:\\Github\\ICRA_25_workshop\\cleaned_task_descriptions.json'\n",
    "        # Open the JSON file and load its contents\n",
    "        with open(task_desc_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Populate the dictionary\n",
    "        for key, value in data.items():\n",
    "            for kw in self.keywords:\n",
    "                if kw in value.lower():\n",
    "                    self.selected_task_dict[kw].append(key)\n",
    "\n",
    "    def _get_all_task_dirs(self, action):\n",
    "        \"\"\"Get all task directories in the dataset\"\"\"\n",
    "        task_file = []\n",
    "        for item in os.listdir(self.data_path):\n",
    "            if item.startswith('task_') and not item.endswith('_human') and not item.endswith('_2'):\n",
    "                if item.split('_')[1] in self.selected_task_dict[action]:\n",
    "                        task_file.append(item)\n",
    "        self.task_file = task_file\n",
    "\n",
    "    def is_similar_frame(prev_frame, current_frame, threshold=0.95):\n",
    "        grayA = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        grayB = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "        score, _ = ssim(grayA, grayB, full=True)\n",
    "        return score > threshold  # If similarity is high, consider as redundant\n",
    "\n",
    "\n",
    "    def _load_video_frames(self, video_path, depth_path, timestamps, output_dir, csv_file, frame_cut, frame_step=2):\n",
    "        try:\n",
    "            cap1 = cv2.VideoCapture(video_path)\n",
    "            total_frames = int(cap1.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_number = 0\n",
    "            saved_frames = 0\n",
    "            prev_frame = None\n",
    "            timestamps_list = [] \n",
    "            \n",
    "            # Check if file exists to add headers if it's a new file\n",
    "            file_exists = os.path.isfile(csv_file)\n",
    "            \n",
    "            # Prepare data to write\n",
    "            # task_id = split_task[1]\n",
    "            # timestamps = timestamp_new['color']\n",
    "            length = len(timestamps)\n",
    "            rgb_path_out = os.path.join(output_dir, 'rgb')\n",
    "            depth_path_out = os.path.join(output_dir, 'depth')\n",
    "            os.makedirs(rgb_path_out, exist_ok=True)\n",
    "            os.makedirs(depth_path_out, exist_ok=True)\n",
    "\n",
    "            while cap1.isOpened():\n",
    "                ret, frame = cap1.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "\n",
    "                # Extract every 'frame_step' frame to reduce storage\n",
    "                if (frame_number % frame_step == 0) and (frame_number >= frame_step*frame_cut) and (frame_number < length):\n",
    "                    cv2.imwrite(os.path.join(output_dir, 'rgb', f\"{timestamps[frame_number]}.jpg\"), frame, [cv2.IMWRITE_JPEG_QUALITY, 85])\n",
    "                    saved_frames += 1\n",
    "                    timestamps_list.append(timestamps[frame_number])\n",
    "                frame_number += 1\n",
    "\n",
    "                if frame_number >= total_frames:\n",
    "                    break\n",
    "            cap1.release()\n",
    "\n",
    "\n",
    "            cap2 = cv2.VideoCapture(depth_path)\n",
    "            total_frames = int(cap2.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_number = 0\n",
    "            saved_frames = 0\n",
    "            timestamps_list = [] \n",
    "\n",
    "            while cap2.isOpened():\n",
    "                ret, frame = cap2.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                # Extract every 'frame_step' frame to reduce storage\n",
    "                if (frame_number % frame_step == 0) and (frame_number >= frame_step*frame_cut) and (frame_number < length):\n",
    "                    cv2.imwrite(os.path.join(output_dir, 'depth', f\"{timestamps[frame_number]}.jpg\"), frame, [cv2.IMWRITE_JPEG_QUALITY, 85])\n",
    "                    saved_frames += 1\n",
    "                    timestamps_list.append(timestamps[frame_number])\n",
    "                frame_number += 1\n",
    "\n",
    "                if frame_number >= total_frames:\n",
    "                    break\n",
    "            cap2.release()\n",
    "\n",
    "            # Write to CSV\n",
    "            with open(csv_file, \"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "\n",
    "                # Write header if new file\n",
    "                if not file_exists:\n",
    "                    writer.writerow([\"Timestamp\", \"ID\"])\n",
    "\n",
    "                # Write each timestamp with the corresponding task ID\n",
    "                for timestamp in timestamps_list:\n",
    "                    writer.writerow([timestamp, \"\"])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading video: {video_path}, {e}\")\n",
    "\n",
    "\n",
    "    def make_images_from_videos(self, action, camera):\n",
    "        for task in self.task_file:\n",
    "            split_task = task.split('_')\n",
    "            user_scene = '_'.join(split_task[2:6])\n",
    "            dir_path_robot = os.path.join(self.data_path, task, camera)\n",
    "            depth_path_robot = os.path.join(self.depth_path, task, camera)\n",
    "            # Check if the directory exists before proceeding\n",
    "            if os.path.exists(dir_path_robot):\n",
    "                # outputdir_robot = os.path.join(self.root_dir_output, 'robot', camera, action, split_task[1], user_scene, 'frames')\n",
    "                outputdir_robot = os.path.join(self.root_dir_output, 'robot', camera, action, split_task[1], user_scene)\n",
    "                os.makedirs(outputdir_robot, exist_ok=True)\n",
    "                video_path_rgb_robot = os.path.join(dir_path_robot, 'color.mp4')\n",
    "                video_depth_path_robot = os.path.join(depth_path_robot, 'depth.mp4')\n",
    "                # timestamp_path = os.path.join(dir_path_robot, 'timestamps.npy')\n",
    "                timestamp_path = os.path.join(self.data_path, task, 'cam_104122061850', 'timestamps.npy')\n",
    "                timestamps = np.load(timestamp_path, allow_pickle=True)\n",
    "                timestamp_new = timestamps.item() \n",
    "\n",
    "                csv_filename_robot = os.path.join(self.root_dir_output, 'robot', camera, action, \"data.csv\")\n",
    "                # Create directory for output\n",
    "                os.makedirs(os.path.dirname(csv_filename_robot), exist_ok=True)\n",
    "\n",
    "                self._load_video_frames(video_path_rgb_robot, video_depth_path_robot, timestamp_new['color'], outputdir_robot, csv_filename_robot, frame_cut=13)\n",
    "\n",
    "            dir_path_human = os.path.join(self.data_path, task+'_human', camera)\n",
    "            depth_path_human = os.path.join(self.depth_path, task+'_human', camera)\n",
    "            # Check if the directory exists before proceeding\n",
    "            if os.path.exists(dir_path_human):\n",
    "                # outputdir_human = os.path.join(self.root_dir_output, 'human', camera, action, split_task[1], user_scene, 'frames')\n",
    "                outputdir_human = os.path.join(self.root_dir_output, 'human', camera, action, split_task[1], user_scene)\n",
    "                os.makedirs(outputdir_human, exist_ok=True)\n",
    "                video_path_rgb_human = os.path.join(dir_path_human, 'color.mp4')\n",
    "                video_depth_path_human = os.path.join(depth_path_human, 'depth.mp4')\n",
    "                # timestamp_path = os.path.join(dir_path_human, 'timestamps.npy')\n",
    "                timestamp_path = os.path.join(self.data_path, task+'_human', 'cam_104122061850', 'timestamps.npy')\n",
    "                timestamps = np.load(timestamp_path, allow_pickle=True)\n",
    "                timestamp_new = timestamps.item()\n",
    "\n",
    "                csv_filename_human = os.path.join(self.root_dir_output, 'human', camera, action, \"data.csv\")\n",
    "                # Create directory for output\n",
    "                os.makedirs(os.path.dirname(csv_filename_human), exist_ok=True)\n",
    "\n",
    "                self._load_video_frames(video_path_rgb_human, video_depth_path_human, timestamp_new['color'], outputdir_human, csv_filename_human, frame_cut=18)\n",
    "\n",
    "    def load_save_proprio_data(self, data_dir, cam, outdir):\n",
    "        camera = cam.split('_')[1]\n",
    "        \n",
    "        tcp_path = os.path.join(data_dir, 'tcp.npy')\n",
    "        tcp = np.load(tcp_path, allow_pickle=True)\n",
    "        tcp = tcp.item()\n",
    "        tcp_camera = tcp[camera]\n",
    "        np.save(os.path.join(outdir, 'tcp.npy'), tcp_camera) \n",
    "\n",
    "        gripper_path = os.path.join(data_dir, 'gripper.npy')\n",
    "        gripper = np.load(gripper_path, allow_pickle=True)\n",
    "        gripper = gripper.item()\n",
    "        gripper_camera = gripper[camera]\n",
    "        np.save(os.path.join(outdir, 'gripper.npy'), gripper_camera)\n",
    "\n",
    "        force_torque_path = os.path.join(data_dir, 'force_torque.npy')\n",
    "        force_torque = np.load(force_torque_path, allow_pickle=True)\n",
    "        force_torque = force_torque.item()\n",
    "        force_torque_camera = force_torque[camera]\n",
    "        np.save(os.path.join(outdir, 'force_torque.npy'), force_torque_camera)\n",
    "\n",
    "    def generate_proprioceptive_data(self, action, camera):\n",
    "        for task in self.task_file:\n",
    "            split_task = task.split('_')\n",
    "            user_scene = '_'.join(split_task[2:6])\n",
    "            dir_path_robot = os.path.join(self.data_path, task, 'transformed')\n",
    "            outputdir_robot = os.path.join(self.root_dir_output, 'robot', camera, action, split_task[1], user_scene)\n",
    "            os.makedirs(outputdir_robot, exist_ok=True)\n",
    "\n",
    "            self.load_save_proprio_data(dir_path_robot, camera, outputdir_robot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RH20TDataset(r\"E:\\Neuro_Sym_AI\\RH20T_cfg2\\RH20T_cfg2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nsai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
